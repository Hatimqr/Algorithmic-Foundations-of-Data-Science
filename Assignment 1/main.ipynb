{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0679dc1",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "Assumptions:\n",
    "1. If there is a line (x, y), there will not be another line with (y, x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91583038",
   "metadata": {},
   "source": [
    "## Part A\n",
    "\n",
    "\n",
    "Map function:\n",
    "$$\n",
    "map : (null, (x,y)) \\rightarrow [(x, 1), (y, 1)]\n",
    "$$\n",
    "Reduce function:\n",
    "$$\n",
    "reduce : (x, [1, 1, ...]) \\rightarrow (x, sum([1, 1, ...]))\n",
    "$$\n",
    "\n",
    "The file would have each line: $x, \\text{count\\_of\\_friends}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d047fd22",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "### Phase 1\n",
    "\n",
    "Map function:\n",
    "$$\n",
    "map : (null, (x,y)) \\rightarrow [(x, y), (y, x)]\n",
    "$$\n",
    "\n",
    "\n",
    "Reduce function (identity):\n",
    "$$\n",
    "reduce : (x, [y_1, y_2, ...]) \\rightarrow (x, [y_1, y_2, ...])\n",
    "$$\n",
    "\n",
    "\n",
    "### Intemediary Step (optional)\n",
    "Filter out all pairs where the length of the friend list < k\n",
    "\n",
    "\n",
    "### Phase 2\n",
    "\n",
    "Map Function:\n",
    "$$\n",
    "map : (x_i, [y_1, y_2, ...]) \\rightarrow ((y_i, y_j), 1) \\forall i,j, i \\neq j\n",
    "$$\n",
    "\n",
    "Additionally, we also need to remove duplicates like $(y_i, y_j)$ and $(y_j, y_i)$. We can do this my sorting the pairs in alphabetically order and then removing the duplicates.\n",
    "\n",
    "Reduce Function:\n",
    "$$\n",
    "reduce : ((y_i, y_j), [1,1,...]) \\rightarrow ((y_i, y_j), sum([1,1,...]))\n",
    "$$\n",
    "Write the $(y_i, y_j)$ pairs that have key $\\geq 7$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f52cd2",
   "metadata": {},
   "source": [
    "## Part C\n",
    "\n",
    "Map function:\n",
    "$$\n",
    "map: (x,y) \\rightarrow ((x, 1), (y, 1))\n",
    "$$\n",
    "Reduce function:\n",
    "$$\n",
    "reduce: (x, [1, 1, ...]) \\rightarrow \n",
    "\\begin{cases}\n",
    "    (x, \\text{null}) & \\text{with probability } 0.01 \\\\\n",
    "    \\text{nothing} & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "​\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beed102",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9b225e",
   "metadata": {},
   "source": [
    "## Part A\n",
    "\n",
    "Consider the computation of $m_n = min{a_1, a_2, ..., a_n}$. In a single MapReduce pass, some reducer, let's call it $R_n$, must be responsible for computing and outputting the pair $(n, m_n)$.\n",
    "\n",
    "Assume the input to reducer $R_n$ is determined by fewer than $n$ of the original input values. This implies there exists at least one input $a_j$ (for some $j \\in \\{1, ..., n\\}$) that provides no information to $R_n$.\n",
    "\n",
    "But this contradicts the definition of $R_n$ because it must use all $n$ input values to compute $m_n$ correctly. Therefore, the input to $R_n$ must be exactly the sequence $(a_1, ..., a_n)$ and the reducer size is $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e4a89",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "### Idea\n",
    "First we make a key observation. To compute $m_i$, we can do $m_i = min/{m_{i-1}, a_i/}$ instead of comparing all $a_k$ where $k < i$.\n",
    "\n",
    "We can do 2 logical steps as follows:\n",
    "1. Split the input sequence into $\\frac{n}{sqrt{n}}$ equal and ordered chunks and compute the min for the largest index in the chunk. \n",
    "2. now we will have $\\sqrt{n}$ pairs of local minima and we perform the naive version of the algorithm but instead of using all $a_i$ we use only the $a_i$'s that are greater than the largest $m_i$ before the target $m_i$. Additionally we must use all the previous $m_i$'s as well (but we could compute a running minima of all intermediate m_i's given a third pass). This will make the reducer size in the second pass as most $(\\sqrt{n}-1)+(\\sqrt{n}-1)$ (the second to last element) which is still $O(\\sqrt{n})$\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "#### Pass 1 - chunk mins\n",
    "\n",
    "Break array $A$ into $\\sqrt{n}$ equal and ordered chunks $C_1,C_2,…,C_{\\sqrt{n}}$. For the mapping function we need to be able to map $i$ to a chunk id $c_i$. We do this as follows:\n",
    "\n",
    "$$c_i=\\lceil \\frac{i}{\\sqrt{n}} \\rceil$$\n",
    "\n",
    "\n",
    "Mapping function:\n",
    "$$\n",
    "map : (i, a_i) \\mapsto (c_i, a_i)\n",
    "$$\n",
    "\n",
    "Reduce function:\n",
    "$$\n",
    "reduce: (c_i, [a_i, ... , a_{i+\\sqrt{n}-1}]) \\mapsto (c_i, M_i)\n",
    "$$\n",
    "where $M_i = \\min\\{[a_i, ... , a_{i+\\sqrt{n}-1}]\\}$\n",
    "\n",
    "\n",
    "\n",
    "#### Pass 2 - Assemble\n",
    "\n",
    "We now have inputs:\n",
    "1. $(c_j, M_j)$\n",
    "2. $(i, a_i)$\n",
    "\n",
    "Mapping Function:\n",
    "$$\n",
    "map: (i, a_i) \\mapsto (c_i, ('val', i, a_i)) \\newline\n",
    "map: (c_j, M_j) \\mapsto (c_{k}, ('min', M_j)) \\space \\forall c_k>c_j\n",
    "$$\n",
    "\n",
    "After the shuffle phase:\n",
    " $$(c_i, [('min', M_1), ... , ('min', M_{i-\\sqrt{n}})], ('val', i, a_i), ... , ('val', i+\\sqrt{n}, a_{i+\\sqrt{n}}))$$\n",
    "\n",
    "Reduce Function:\n",
    "\n",
    "Each reducer is responsible for a single chunk $c_i$\n",
    "1. Calculate the running minimum from all minimum chunks:\n",
    "$$\n",
    "P = \\min\\{M_j | ('min', M_j) \\in list\\}\n",
    "$$\n",
    "\n",
    "2. Initialize local_min as P (if no 'min' tuples like in the first chunk, initialise to infinity)\n",
    "3. Sort the value tuples $('val', i, a_i)$ by $i$\n",
    "4. Iterate through the sorted value tuples\n",
    "    - for each $('val', i, a_i)$:\n",
    "        - update $local_min = min(local_min, a_i)$\n",
    "        - emit the final pair $(i, local_min)$\n",
    "\n",
    "We then combine the lists from all reducers and return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becb3397",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "Assumption:\n",
    "- We are using a single machine for subsumpling but we could potentially distribute it. However, this will be order of n, so no effect on the big O of communication cost.\n",
    "- We assume that when we sample we produce dividers that are roughly equal size. This is a fair assumption if we take k to be large enough to preserve the distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12216f60",
   "metadata": {},
   "source": [
    "## Part A\n",
    "\n",
    "The goal is to broadcast $x_0, ... x_{k+1}$ (k+2) numbers to t machines. \n",
    "\n",
    "The subsampling happens on the master so there is no communication cost involved. We simply pick each number with probability $k/n$.\n",
    "The broadcast is the only phase we have a communication cost.\n",
    "\n",
    "This means we are sending a total of $(k+2)\\times t = kt \\times 2t$ numbers in total. This is $O(kt)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958df34c",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "The goal here is to compute how many numbers fall into each of the $k$ buckets (exist on each machine).\n",
    "\n",
    "First we count the number of elements in each bucket on each of the $t$ local machines. We end up with a count for each of the $k$ buckets.\n",
    "\n",
    "Next, we need to transmit this count back to the master to sum up the total number of elements in each bucket. Here, we send $k$ (or 2k if we are sending pairs) numbers to the master from each of the $t$ machines. $G_i$ is then the sum of the count sent from each machine for each bucket.\n",
    "\n",
    "Thus, in total we are sending at most $2k \\times t$ numbers across the network which is $O(kt)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355d021b",
   "metadata": {},
   "source": [
    "## Part C\n",
    "\n",
    "The goal here is to use the global counts that we have from the master to figure out which $G_i$ contains the median and then which element in $G_i$ is the median ($r$).\n",
    "\n",
    "We now have $(n_i, count_i)$ on the master. Wer can find $G_i$ and $r$ as follows:\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\text{1. Calculate the median's overall rank}\\\\\n",
    "&N = \\sum \\text{counts}\\\\\n",
    "&\\text{median\\_rank} = \\lceil N / 2 \\rceil\\\\\n",
    "\\\\\n",
    "&\\text{2. Find the bucket containing the median}\\\\\n",
    "&\\text{cumulative\\_count} = 0\\\\\n",
    "&\\text{for } j \\text{ from } 0 \\text{ to length(counts)} - 1\\text{:}\\\\\n",
    "&\\quad\\text{// Check if the median falls within the current bucket}\\\\\n",
    "&\\quad\\text{if } (\\text{cumulative\\_count} + \\text{counts}[j]) \\geq \\text{median\\_rank}\\text{:}\\\\\n",
    "&\\quad\\quad\\text{// 3. Calculate the rank 'r' within this bucket}\\\\\n",
    "&\\quad\\quad r = \\text{median\\_rank} - \\text{cumulative\\_count}\\\\\n",
    "&\\quad\\quad\\text{return } (j, r) \\text{ // Return the bucket index and the rank}\\\\\n",
    "\\\\\n",
    "&\\quad\\text{// If not found, add the current bucket's count to the total}\\\\\n",
    "&\\quad\\text{cumulative\\_count} = \\text{cumulative\\_count} + \\text{counts}[j]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "There is no communication cost since this is all done on the master."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb4e762",
   "metadata": {},
   "source": [
    "## Part D\n",
    "\n",
    "We now know $G_j$ and $r$ so we need to collect an ordered list of numbers in $G_j$ to find the median. \n",
    "\n",
    "The master instructs all $t$ machines to send it only the numbers they have that belong to bucket $G_j$. The total communication is the total number of elements in $G_j$, which is $n_j$.\n",
    "\n",
    "The network cost would be the expected size of $n_j$. Since we chose $k$ samples, the data would be divided into $k+1$ chunks of roughly equal size on average.\n",
    "\n",
    "Thus the network communication cost is approximately $\\frac{n}{k+1}$ which is $O(\\frac{n}{k})$\n",
    "\n",
    "Once the master has the list of numbers in $G_j$, we sort it and return the element at index $r$. This is the median.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2116a9",
   "metadata": {},
   "source": [
    "## Part E\n",
    "\n",
    "From the above parts we know communication cost is:\n",
    "$$\n",
    "Total Cost(k) \\approx O(kt) + O(kt) + O(n/k) = O(kt + n/k)\n",
    "$$\n",
    "\n",
    "To minimize network cost we need to find $k$ that minimizes $f(k)=kt + n/k$\n",
    "\n",
    "$$\n",
    "f'(k) = t-\\frac{n}{k^2} \n",
    "$$\n",
    "Set $f'(k) = 0$ to find the minimum:\n",
    "$$\n",
    "0 = t-\\frac{n}{k^2} \\newline\n",
    "k^2=\\frac{n}{t} \\newline\n",
    "k = \\sqrt{\\frac{n}{t}}\n",
    "$$\n",
    "\n",
    "Thus we choose $k = \\sqrt{\\frac{n}{t}}$ to minimize network cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dab23e",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db500f38",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "794d4d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for Spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "spark_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.4\n",
      "Spark UI available at: http://10.228.244.25:4040\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark session for local machine\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Assignment1_Problem4\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to basically no verbose output\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Spark UI available at: {spark.sparkContext.uiWebUrl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b966733",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasources = {\n",
    "    'links' : spark.read.csv('data/links.csv', header=True, inferSchema=True),\n",
    "    'movies' : spark.read.csv('data/movies.csv', header=True, inferSchema=True),\n",
    "    'ratings' : spark.read.csv('data/ratings.csv', header=True, inferSchema=True),\n",
    "    'tags' : spark.read.csv('data/tags.csv', header=True, inferSchema=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30d655e",
   "metadata": {},
   "source": [
    "## Part A\n",
    "- Code Function: Calculates the mean number of ratings received per movie across the entire dataset.\n",
    "- Implementation:\n",
    "    - Groups ratings by movieID and counts ratings per movie\n",
    "    - Computes the overall average of these counts\n",
    "    - Output: 10.37 ratings per movie on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46f3c11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of ratings per movie:  10.369806663924312\n"
     ]
    }
   ],
   "source": [
    "df = datasources['ratings']\n",
    "\n",
    "avg_count = (\n",
    "    df.groupBy('movieID').agg(count('rating').alias('count')) #count ratings for each movie\n",
    "    .agg(avg('count')) # get the average counts\n",
    "    .collect()[0][0] # get the average\n",
    ")\n",
    "print('Average number of ratings per movie: ',avg_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb6612",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "\n",
    "- Code Function: Determines which movie genres receive the highest average ratings from users.\n",
    "- Implementation:\n",
    "    - Joins ratings and movies datasets on movieID\n",
    "    - Splits pipe-separated genres (Action|Comedy|Drama) into individual rows using explode()\n",
    "    - Each movie has many genres. we will assume that the movie appears in all of the genres it is classified in as a single entry to compute the average rating of the genre.\n",
    "    - Groups by genre and calculates average rating\n",
    "    - Sorts results in descending order\n",
    "- Key Findings:\n",
    "    - Film-Noir (3.92) - Highest rated genre\n",
    "    - War (3.81) - Second highest\n",
    "    - Documentary (3.80) - Third highest\n",
    "    - Horror (3.26) - Lowest rated genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfad1eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|            genres|        avg_rating|\n",
      "+------------------+------------------+\n",
      "|         Film-Noir| 3.920114942528736|\n",
      "|               War|   3.8082938876312|\n",
      "|       Documentary| 3.797785069729286|\n",
      "|             Crime| 3.658293867274144|\n",
      "|             Drama|3.6561844113718758|\n",
      "|           Mystery| 3.632460255407871|\n",
      "|         Animation|3.6299370349170004|\n",
      "|              IMAX| 3.618335343787696|\n",
      "|           Western| 3.583937823834197|\n",
      "|           Musical|3.5636781053649105|\n",
      "|         Adventure|3.5086089151939075|\n",
      "|           Romance|3.5065107040388437|\n",
      "|          Thriller|3.4937055799183425|\n",
      "|           Fantasy|3.4910005070136894|\n",
      "|(no genres listed)|3.4893617021276597|\n",
      "|            Sci-Fi| 3.455721162210752|\n",
      "|            Action| 3.447984331646809|\n",
      "|          Children| 3.412956125108601|\n",
      "|            Comedy|3.3847207640898267|\n",
      "|            Horror| 3.258195034974626|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies = datasources['movies']\n",
    "ratings = datasources['ratings']\n",
    "\n",
    "# join genre on movie id in ratings\n",
    "df = (\n",
    "    ratings.join(\n",
    "        movies.select('movieID', 'genres'),\n",
    "        on='movieID', \n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "# explode the genres column\n",
    "df = (df\n",
    "    # first cast g1|g2|g3 to a list\n",
    "    .withColumn('genres', split('genres', '\\|'))\n",
    "    # explode the list into multiple rows\n",
    "    .withColumn('genres', explode('genres'))\n",
    ")\n",
    "\n",
    "# groupby and get average rating for each genre\n",
    "genre_avg = (\n",
    "    df.groupBy('genres')\n",
    "    .agg(avg('rating').alias('avg_rating')) # get average rating for each genre\n",
    "    .sort('avg_rating', ascending=False) # sort by average rating\n",
    ")\n",
    "\n",
    "genre_avg.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2cd7bf",
   "metadata": {},
   "source": [
    "## Part C\n",
    "- Code Function: Identifies the highest-rated movies within each genre category.\n",
    "- Implementation:\n",
    "    - Similar genre explosion technique as Part B\n",
    "    - Groups by movieID, title, and genres to get per-movie averages\n",
    "    - Uses window functions (row_number() with partitionBy) to rank movies within each genre\n",
    "    - Filters to show only top 3 movies per genre\n",
    "- Key Findings:\n",
    "    - Many genres have multiple movies with perfect 5.0 ratings\n",
    "    - Examples include \"Black Mirror\", \"Sonatine\", \"12 Chairs (1976)\"\n",
    "    - Shows that niche or less-rated movies can achieve perfect scores\n",
    "- Technical Note: The ranking uses row_number() over a window partitioned by genre and ordered by average rating (descending)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d04f4ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----------------+----+\n",
      "|               title|            genres|       avg_rating|rank|\n",
      "+--------------------+------------------+-----------------+----+\n",
      "|        Black Mirror|(no genres listed)|              5.0|   1|\n",
      "|Death Note: Desu ...|(no genres listed)|              5.0|   2|\n",
      "|The Adventures of...|(no genres listed)|              5.0|   3|\n",
      "|Sonatine (Sonachi...|            Action|              5.0|   1|\n",
      "|    Knock Off (1998)|            Action|              5.0|   2|\n",
      "|    Max Manus (2008)|            Action|              5.0|   3|\n",
      "|    12 Chairs (1976)|         Adventure|              5.0|   1|\n",
      "|Junior and Karlso...|         Adventure|              5.0|   2|\n",
      "|Asterix and the V...|         Adventure|              5.0|   3|\n",
      "|My Life as McDull...|         Animation|              5.0|   1|\n",
      "|Into the Forest o...|         Animation|              5.0|   2|\n",
      "|Winnie the Pooh a...|         Animation|              5.0|   3|\n",
      "|The Fox and the H...|          Children|              5.0|   1|\n",
      "|Wow! A Talking Fi...|          Children|              5.0|   2|\n",
      "|Junior and Karlso...|          Children|              5.0|   3|\n",
      "|Unfaithfully Your...|            Comedy|              5.0|   1|\n",
      "|What Happened Was...|            Comedy|              5.0|   2|\n",
      "|       Presto (2008)|            Comedy|              5.0|   3|\n",
      "|American Friend, ...|             Crime|              5.0|   1|\n",
      "|Little Murders (1...|             Crime|              5.0|   2|\n",
      "|Trailer Park Boys...|             Crime|              5.0|   3|\n",
      "|Tickling Giants (...|       Documentary|              5.0|   1|\n",
      "|Zeitgeist: Moving...|       Documentary|              5.0|   2|\n",
      "|Martin Lawrence L...|       Documentary|              5.0|   3|\n",
      "|Sisters (Syostry)...|             Drama|              5.0|   1|\n",
      "|Thousand Clowns, ...|             Drama|              5.0|   2|\n",
      "|Duel in the Sun (...|             Drama|              5.0|   3|\n",
      "| L.A. Slasher (2015)|           Fantasy|              5.0|   1|\n",
      "|       Presto (2008)|           Fantasy|              5.0|   2|\n",
      "|My Left Eye Sees ...|           Fantasy|              5.0|   3|\n",
      "|Rififi (Du rififi...|         Film-Noir|             4.75|   1|\n",
      "|Long Goodbye, The...|         Film-Noir|4.666666666666667|   2|\n",
      "|You Only Live Onc...|         Film-Noir|              4.5|   3|\n",
      "| Maniac Cop 2 (1990)|            Horror|              5.0|   1|\n",
      "|      Buzzard (2015)|            Horror|              5.0|   2|\n",
      "|Galaxy of Terror ...|            Horror|              5.0|   3|\n",
      "|         More (1998)|              IMAX|              5.0|   1|\n",
      "|Happy Feet Two (2...|              IMAX|              5.0|   2|\n",
      "|Journey to the We...|              IMAX|             4.75|   3|\n",
      "|Woman Is a Woman,...|           Musical|              5.0|   1|\n",
      "|Into the Woods (1...|           Musical|              5.0|   2|\n",
      "| True Stories (1986)|           Musical|              5.0|   3|\n",
      "| 'Salem's Lot (2004)|           Mystery|              5.0|   1|\n",
      "|The Adventures of...|           Mystery|              5.0|   2|\n",
      "|7 Faces of Dr. La...|           Mystery|              5.0|   3|\n",
      "|Moscow Does Not B...|           Romance|              5.0|   1|\n",
      "|Crossing Delancey...|           Romance|              5.0|   2|\n",
      "|My Left Eye Sees ...|           Romance|              5.0|   3|\n",
      "|SORI: Voice from ...|            Sci-Fi|              5.0|   1|\n",
      "|Mystery of the Th...|            Sci-Fi|              5.0|   2|\n",
      "|A Detective Story...|            Sci-Fi|              5.0|   3|\n",
      "|Supercop 2 (Proje...|          Thriller|              5.0|   1|\n",
      "|  Hellbenders (2012)|          Thriller|              5.0|   2|\n",
      "| Maniac Cop 2 (1990)|          Thriller|              5.0|   3|\n",
      "|     Mephisto (1981)|               War|              5.0|   1|\n",
      "|Come and See (Idi...|               War|              5.0|   2|\n",
      "|Battle Royale 2: ...|               War|              5.0|   3|\n",
      "|Duel in the Sun (...|           Western|              5.0|   1|\n",
      "|Trinity and Sarta...|           Western|              5.0|   2|\n",
      "|7 Faces of Dr. La...|           Western|              5.0|   3|\n",
      "+--------------------+------------------+-----------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies = datasources['movies']\n",
    "ratings = datasources['ratings']\n",
    "\n",
    "# we need ratings, movies, and genres\n",
    "df = (\n",
    "    ratings.join(\n",
    "        movies.select('movieID', 'genres', 'title'),\n",
    "        on='movieID',\n",
    "        how='left'\n",
    "    )\n",
    ")\n",
    "\n",
    "# explode the genres column\n",
    "df = (df\n",
    "    # first cast g1|g2|g3 to a list\n",
    "    .withColumn('genres', split('genres', '\\|'))\n",
    "    # explode the list into multiple rows\n",
    "    .withColumn('genres', explode('genres'))\n",
    ")\n",
    "\n",
    "movie_avg = (\n",
    "    df.groupBy('movieID', 'title', 'genres')\n",
    "    .agg(avg('rating').alias('avg_rating')) # get average rating for each movie\n",
    "    # keep only the top 3 movies in each genre\n",
    "    .withColumn('rank', \n",
    "        row_number().over(Window.partitionBy('genres').orderBy(desc('avg_rating'))))\n",
    "    .filter('rank <= 3')\n",
    "    .sort('genres', 'rank')\n",
    "    .drop('movieID')\n",
    ")\n",
    "\n",
    "movie_avg.show(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291c620",
   "metadata": {},
   "source": [
    "## Part D\n",
    "- Code Function: Identifies users who have rated the most movies.\n",
    "- Implementation:\n",
    "    - Groups ratings by userID and counts total ratings per user\n",
    "    - Sorts in descending order by count\n",
    "- Key Findings:\n",
    "    - User 414: Most active with 2,698 ratings\n",
    "    - User 599: Second with 2,478 ratings\n",
    "    - User 474: Third with 2,108 ratings\n",
    "    - Top 10 users range from 1,055 to 2,698 ratings\n",
    "- Insight: Shows significant variation in user engagement, with power users rating hundreds more movies than typical users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "851ece07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|userID|count_rated|\n",
      "+------+-----------+\n",
      "|   414|       2698|\n",
      "|   599|       2478|\n",
      "|   474|       2108|\n",
      "|   448|       1864|\n",
      "|   274|       1346|\n",
      "|   610|       1302|\n",
      "|    68|       1260|\n",
      "|   380|       1218|\n",
      "|   606|       1115|\n",
      "|   288|       1055|\n",
      "+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = datasources['ratings']\n",
    "\n",
    "user_movies = (\n",
    "    ratings.select('userID', 'movieID')\n",
    "    .groupBy('userID')\n",
    "    .agg(count('movieID').alias('count_rated')) # count num ratings for each user\n",
    "    .sort('count_rated', ascending=False) # sort by num ratings\n",
    ")\n",
    "\n",
    "user_movies.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18993e6b",
   "metadata": {},
   "source": [
    "## Part E\n",
    "- Code Function: Finds pairs of users with the most movies rated in common (collaborative filtering foundation).\n",
    "- Implementation:\n",
    "    - Creates user-movie lists using collect_list() aggregation\n",
    "    - Performs cross-join between users to create all possible user pairs\n",
    "    - Uses array_intersect() to find common movies between user pairs\n",
    "    - Calculates intersection cardinality and ranks by similarity\n",
    "- Key Findings:\n",
    "    - Users 414 & 599: Highest similarity with 1,338 movies in common\n",
    "    - Users 414 & 474: Second highest with 1,077 movies in common\n",
    "    - User 414 appears frequently in top pairs (consistent with being most active)\n",
    "    - Technical Significance: This analysis forms the basis for collaborative filtering recommender systems, where users with similar viewing histories receive similar recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87e2ebbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users: 610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 77:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------------------+\n",
      "|user_1|user_2|intersection_cardinality|\n",
      "+------+------+------------------------+\n",
      "|   414|   599|                    1338|\n",
      "|   599|   414|                    1338|\n",
      "|   414|   474|                    1077|\n",
      "|   474|   414|                    1077|\n",
      "|    68|   414|                     950|\n",
      "|   414|    68|                     950|\n",
      "|   414|   448|                     914|\n",
      "|   448|   414|                     914|\n",
      "|   274|   414|                     856|\n",
      "|   414|   274|                     856|\n",
      "+------+------+------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ratings = datasources['ratings']\n",
    "\n",
    "print('num_users:',ratings.select('userID').agg(countDistinct('userID')).collect()[0][0])\n",
    "\n",
    "# first we get a dataframe with (userID, list_of_movies_rated)\n",
    "user_movies = (\n",
    "    ratings.select('userID', 'movieID')\n",
    "    .groupBy('userID')\n",
    "    .agg(collect_list('movieID').alias('movies_rated'))\n",
    ")\n",
    "\n",
    "# now we need to check for every user pair what the intersection of their movies is\n",
    "# first do a cross join and remove rows where user1 == user2\n",
    "user_pairs = (\n",
    "    user_movies.alias('u1')\n",
    "    .crossJoin(user_movies.alias('u2'))\n",
    "    .filter('u1.userID != u2.userID')\n",
    "    .select(\n",
    "        col('u1.userID').alias('userID_u1'),\n",
    "        col('u1.movies_rated').alias('movies_rated_u1'),\n",
    "        col('u2.userID').alias('userID_u2'),\n",
    "        col('u2.movies_rated').alias('movies_rated_u2')\n",
    "    )\n",
    ")\n",
    "\n",
    "# now we need to create another column with the intersection between movies_rated_u1 and movies_rated_u2\n",
    "# also get the cardinality of the intersection\n",
    "user_pairs = (\n",
    "    user_pairs\n",
    "    .withColumn(\n",
    "        'movies_rated_intersection',\n",
    "        array_intersect('movies_rated_u1', 'movies_rated_u2')\n",
    "    )\n",
    "    .withColumn(\n",
    "        'intersection_cardinality',\n",
    "        size('movies_rated_intersection')\n",
    "    )\n",
    ")\n",
    "\n",
    "# rename cols and drop unnessary columns. sort by intersection_cardinality\n",
    "user_pairs = (\n",
    "    user_pairs\n",
    "    .withColumnRenamed('userID_u1', 'user_1')\n",
    "    .withColumnRenamed('userID_u2', 'user_2')\n",
    "    .drop('movies_rated_u1', 'movies_rated_u2', 'movies_rated_intersection')\n",
    "    .sort('intersection_cardinality', ascending=False)\n",
    ")\n",
    "\n",
    "\n",
    "user_pairs.show(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
